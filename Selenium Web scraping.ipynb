{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import csv\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a new .csv file that the data will be written to\n",
    "csv_file = open('airline_reviews.csv', 'w', encoding=\"utf-8\")\n",
    "writer = csv.writer(csv_file)\n",
    "\n",
    "# Define the variables (future data frame columns) to be scraped\n",
    "writer.writerow(['airline', 'overall', 'author', 'review_date', 'customer_review', 'aircraft', 'traveller_type', 'cabin', 'route', 'date_flown', 'seat_comfort', 'cabin_service', 'food_bev', 'entertainment', 'ground_service', 'value_for_money', 'recommended'])\n",
    "\n",
    "path = r\"C:/Users/hp/Downloads/chromedriver_win32/chromedriver.exe\"\n",
    "#path = \"/Users/Athena Zhang/Downloads/chromedriver\"\n",
    "#driver = webdriver.Edge(path)\n",
    "driver = webdriver.Chrome(path)\n",
    "driver.get(\"https://www.airlinequality.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# US_airlines is a list of all the webpage endings corresponding to the pages for the airlines I want to get reviews for\n",
    "US_airlines = [\"southwest-airlines/\"]\n",
    "\n",
    "# Get the actual URLs with a list comprehension using the above list\n",
    "US_airline_pages = [\"http://www.airlinequality.com/airline-reviews/\" + airline for airline in US_airlines]\n",
    "#driver.get(\"http://www.airlinequality.com/review-pages/a-z-airline-reviews/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Scraping http://www.airlinequality.com/airline-reviews/southwest-airlines/\n",
      "Scraping Page number 1\n",
      "Scraping Page number 2\n",
      "Scraping Page number 3\n",
      "Scraping Page number 4\n",
      "Scraping Page number 5\n",
      "Scraping Page number 6\n",
      "Scraping Page number 7\n",
      "Scraping Page number 8\n",
      "Scraping Page number 9\n",
      "Scraping Page number 10\n",
      "Scraping Page number 11\n",
      "Scraping Page number 12\n",
      "Scraping Page number 13\n",
      "Scraping Page number 14\n",
      "Scraping Page number 15\n",
      "Scraping Page number 16\n",
      "Scraping Page number 17\n",
      "Scraping Page number 18\n",
      "Scraping Page number 19\n",
      "Scraping Page number 20\n",
      "Scraping Page number 21\n",
      "Scraping Page number 22\n",
      "Scraping Page number 23\n",
      "Scraping Page number 24\n",
      "Scraping Page number 25\n",
      "Scraping Page number 26\n",
      "Scraping Page number 27\n",
      "Scraping Page number 28\n",
      "Scraping Page number 29\n",
      "Scraping Page number 30\n",
      "Scraping Page number 31\n",
      "Scraping Page number 32\n",
      "Scraping Page number 33\n",
      "Scraping Page number 34\n",
      "Scraping Page number 35\n",
      "Scraping Page number 36\n",
      "Scraping Page number 37\n",
      "Scraping Page number 38\n",
      "Scraping Page number 39\n",
      "Scraping Page number 40\n",
      "Scraping Page number 41\n",
      "Scraping Page number 42\n",
      "Scraping Page number 43\n",
      "Scraping Page number 44\n",
      "Scraping Page number 45\n",
      "Scraping Page number 46\n",
      "Scraping Page number 47\n",
      "Scraping Page number 48\n",
      "Scraping Page number 49\n",
      "Scraping Page number 50\n",
      "Scraping Page number 51\n",
      "Scraping Page number 52\n",
      "Scraping Page number 53\n",
      "Scraping Page number 54\n",
      "Scraping Page number 55\n",
      "Scraping Page number 56\n",
      "Scraping Page number 57\n",
      "Scraping Page number 58\n",
      "Scraping Page number 59\n",
      "Scraping Page number 60\n",
      "Scraping Page number 61\n",
      "Scraping Page number 62\n",
      "Scraping Page number 63\n",
      "Scraping Page number 64\n",
      "Scraping Page number 65\n",
      "Scraping Page number 66\n",
      "Scraping Page number 67\n",
      "Scraping Page number 68\n",
      "Scraping Page number 69\n",
      "Scraping Page number 70\n",
      "Scraping Page number 71\n",
      "Scraping Page number 72\n",
      "Scraping Page number 73\n",
      "Scraping Page number 74\n",
      "Scraping Page number 75\n",
      "Scraping Page number 76\n",
      "Scraping Page number 77\n",
      "Scraping Page number 78\n",
      "Scraping Page number 79\n",
      "Scraping Page number 80\n",
      "Scraping Page number 81\n",
      "Scraping Page number 82\n",
      "Scraping Page number 83\n",
      "Scraping Page number 84\n",
      "Scraping Page number 85\n",
      "Scraping Page number 86\n",
      "Scraping Page number 87\n",
      "Scraping Page number 88\n",
      "Scraping Page number 89\n",
      "Scraping Page number 90\n",
      "Scraping Page number 91\n",
      "Scraping Page number 92\n",
      "Scraping Page number 93\n",
      "Scraping Page number 94\n",
      "Scraping Page number 95\n",
      "Scraping Page number 96\n",
      "Scraping Page number 97\n",
      "Scraping Page number 98\n",
      "Scraping Page number 99\n",
      "Scraping Page number 100\n",
      "Scraping Page number 101\n",
      "Scraping Page number 102\n",
      "Scraping Page number 103\n",
      "Scraping Page number 104\n",
      "Scraping Page number 105\n",
      "Scraping Page number 106\n",
      "Scraping Page number 107\n",
      "Scraping Page number 108\n",
      "Scraping Page number 109\n",
      "Scraping Page number 110\n",
      "Scraping Page number 111\n",
      "Scraping Page number 112\n",
      "Scraping Page number 113\n",
      "Scraping Page number 114\n",
      "Scraping Page number 115\n",
      "Scraping Page number 116\n",
      "Scraping Page number 117\n",
      "Scraping Page number 118\n",
      "Scraping Page number 119\n",
      "Scraping Page number 120\n",
      "Scraping Page number 121\n",
      "Scraping Page number 122\n",
      "Scraping Page number 123\n",
      "Scraping Page number 124\n",
      "Scraping Page number 125\n",
      "Scraping Page number 126\n",
      "Scraping Page number 127\n",
      "Scraping Page number 128\n",
      "Scraping Page number 129\n",
      "Scraping Page number 130\n",
      "Scraping Page number 131\n",
      "Scraping Page number 132\n",
      "Scraping Page number 133\n",
      "Scraping Page number 134\n",
      "Scraping Page number 135\n",
      "Scraping Page number 136\n",
      "Scraping Page number 137\n",
      "Scraping Page number 138\n",
      "Scraping Page number 139\n",
      "Scraping Page number 140\n",
      "Scraping Page number 141\n",
      "Scraping Page number 142\n",
      "Scraping Page number 143\n",
      "Scraping Page number 144\n",
      "Scraping Page number 145\n",
      "Scraping Page number 146\n",
      "Scraping Page number 147\n",
      "Scraping Page number 148\n",
      "Scraping Page number 149\n",
      "Scraping Page number 150\n",
      "Message: target frame detached\n",
      "  (Session info: chrome=101.0.4951.67)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This outer 'for loop' iterates through the different airline websites\n",
    "# The sleep time has been set to 10secs since loading entirely new pages has proven to take longer\n",
    "# than iterating through the pages of reviews within a single airline\n",
    "for page in US_airline_pages:\n",
    "    driver.get(page)\n",
    "    time.sleep(10)\n",
    "    try:\n",
    "        print(\"=\"*40)   #Shows in terminal when a new airline is being scraped \n",
    "        print(\"Scraping \" + page)\n",
    "\n",
    "# Find total number of reviews for the airline\n",
    "# Turn value into a float\n",
    "# Each page defaults to showing 10 reviews, so take the ceiling of the total number of reviews divided by 10 \n",
    "# to get the number of pages of reviews for the airline\n",
    "        review_count = driver.find_element_by_xpath('//div[@class = \"rating-totals\"]//span[@itemprop = \"reviewCount\"]').text\n",
    "        review_count = float(review_count)\n",
    "        n = int(ceil(review_count/10))\n",
    "\n",
    "        # Iterate through all the pages of reviews for the airline in question\n",
    "        index = 1\n",
    "        while index <= n:\n",
    "            driver.get(page + \"page/\" + str(index) +'/')\n",
    "            time.sleep(5)\n",
    "\n",
    "            try:\n",
    "                print(\"Scraping Page number \" + str(index)) \t# Shows in terminal when a new page of reviews is being scraped\n",
    "                index = index + 1\n",
    "\n",
    "               #Find all the reviews:\n",
    "                reviews = driver.find_elements_by_xpath('//article[@itemprop = \"review\"]')\n",
    "                for review in reviews:\n",
    "\n",
    "                    # Initialize an empty dictionary for each review\n",
    "                    review_dict = {}\n",
    "\n",
    "# Find xpaths of the fields desired as columns in future data frame\n",
    "# We use the try/except statements to account for the fact that the reviews are not required to have \n",
    "# all the fields listed below, and if a review does not have a certain field we wish to make the \n",
    "# corresponding field blank in that particular row, rather than quit upon receiving an error. \n",
    "                    try:\n",
    "                        airline = review.find_element_by_xpath('//div[@class = \"review-heading\"]//h1[@itemprop = \"name\"]').text\n",
    "                    except:\n",
    "                        airline = page\n",
    "                    try:\n",
    "                        overall = review.find_element_by_xpath('.//span[@itemprop = \"ratingValue\"]').text\n",
    "                    except: \n",
    "                        overall = \"\"\n",
    "                    try:\n",
    "                        author = review.find_element_by_xpath('.//h3[@class = \"text_sub_header userStatusWrapper\"]//span[@itemprop = \"name\"]').text\n",
    "                    except:\n",
    "                        author = \"\"\n",
    "                    try:\n",
    "                        review_date = review.find_element_by_xpath('.//time[@itemprop = \"datePublished\"]').text\n",
    "                    except:\n",
    "                        review_date = \"\"\n",
    "                    try:\n",
    "                        customer_review = review.find_element_by_xpath('.//div[@itemprop = \"reviewBody\"]').text\n",
    "                    except: \n",
    "                        customer_review = \"\"\n",
    "                    try:\n",
    "                        aircraft_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header aircraft \"]')\n",
    "                        aircraft = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header aircraft \"]/following-sibling::td').text\n",
    "                    except:\n",
    "                        aircraft = \"\"\n",
    "                    try:\n",
    "                        traveller_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header type_of_traveller \"]')\n",
    "                        traveller_type = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header type_of_traveller \"]/following-sibling::td').text\n",
    "                    except:\n",
    "                        traveller_type = \"\"\n",
    "                    try:\n",
    "                        cabin_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header cabin_flown \"]')\n",
    "                        cabin = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header cabin_flown \"]/following-sibling::td').text\n",
    "                    except:\n",
    "                        cabin = \"\"\n",
    "                    try:\n",
    "                        route_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header route \"]')\n",
    "                        route = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header route \"]/following-sibling::td').text\n",
    "                    except:\n",
    "                        route = \"\"\n",
    "                    try:\n",
    "                        date_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header date_flown \"]')\n",
    "                        date_flown = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header date_flown \"]/following-sibling::td').text\n",
    "                    except:\n",
    "                        date_flown = \"\"\n",
    "                    try:\n",
    "                        seat_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header seat_comfort\"]')\n",
    "                        seat_comfort = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header seat_comfort\"]/following-sibling::td/span[@class = \"star fill\"][last()]').text\n",
    "                    except:\n",
    "                        seat_comfort = \"\"\n",
    "                    try:\n",
    "                        cabin_service_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header cabin_staff_service\"]')\n",
    "                        cabin_service = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header cabin_staff_service\"]/following-sibling::td//span[@class = \"star fill\"][last()]').text\n",
    "                    except:\n",
    "                        cabin_service = \"\"\n",
    "                    try:\n",
    "                        food_bev_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header food_and_beverages\"]')\n",
    "                        food_bev = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header food_and_beverages\"]/following-sibling::td//span[@class = \"star fill\"][last()]').text\n",
    "                    except:\n",
    "                        food_bev = \"\"\n",
    "                    try:\n",
    "                        entertainment_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header inflight_entertainment\"]')\n",
    "                        entertainment = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header inflight_entertainment\"]/following-sibling::td//span[@class = \"star fill\"][last()]').text\n",
    "                    except:\n",
    "                        entertainment = \"\"\n",
    "                    try:\n",
    "                        ground_service_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header ground_service\"]')\n",
    "                        ground_service = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header ground_service\"]/following-sibling::td//span[@class = \"star fill\"][last()]').text\n",
    "                    except:\n",
    "                        ground_service = \"\"\n",
    "                    try:\n",
    "                        wifi_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header wifi_and_connectivity\"]')\n",
    "                        wifi = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header wifi_and_connectivity\"]/following-sibling::td//span[@class = \"star fill\"][last()]').text\n",
    "                    except:\n",
    "                        wifi = \"\"\n",
    "                    try:\n",
    "                        value_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header value_for_money\"]')\n",
    "                        value_for_money = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header value_for_money\"]/following-sibling::td//span[@class = \"star fill\"][last()]').text\n",
    "                    except:\n",
    "                        value_for_money = \"\"\n",
    "                    try:\n",
    "                        recommended_label = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header recommended\"]')\n",
    "                        recommended = review.find_element_by_xpath('.//table[@class = \"review-ratings\"]//td[@class = \"review-rating-header recommended\"]/following-sibling::td').text\n",
    "                    except:\n",
    "                        recommended = \"\"\n",
    "\n",
    "# Write the results of the above to a dictionary. Note that each overall review will have its\n",
    "# own dictionary, but all dictionaries for all the rows will all have the same keys. This\n",
    "# allows Selenium to write the contents of these dictionaries into a coherent .csv file\n",
    "                    review_dict['airline'] = airline\n",
    "                    review_dict['overall'] = overall\n",
    "                    review_dict['author'] = author\n",
    "                    review_dict['review_date'] = review_date\n",
    "                    review_dict['customer_review'] = customer_review\n",
    "                    review_dict['aircraft'] = aircraft\n",
    "                    review_dict['traveller_type'] = traveller_type\n",
    "                    review_dict['cabin'] = cabin\n",
    "                    review_dict['route'] = route\n",
    "                    review_dict['date_flown'] = date_flown\n",
    "                    review_dict['seat_comfort'] = seat_comfort\n",
    "                    review_dict['cabin_service'] = cabin_service\n",
    "                    review_dict['food_bev'] = food_bev\n",
    "                    review_dict['entertainment'] = entertainment\n",
    "                    review_dict['ground_service'] = ground_service\n",
    "                    review_dict['value_for_money'] = value_for_money\n",
    "                    review_dict['recommended'] = recommended\n",
    "                    writer.writerow(review_dict.values())\n",
    "\n",
    "# If an error is thrown unrelated to the above variables, print the error to the terminal\n",
    "# console, close the .csv file, and break the while loop.\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                csv_file.close()\n",
    "                #driver.close()\n",
    "                break\n",
    "                \n",
    "    # If an error is thrown between airline pages, print the error to the terminal\n",
    "    # console, close the .csv file, and break the while loop.\n",
    "    except Exception as e:\n",
    "                print(e)\n",
    "                sv_file.close()\n",
    "                #driver.close()\n",
    "                break\n",
    "\n",
    "# Always close your files! \n",
    "csv_file.close()\n",
    "\n",
    "# Optional: close the browser once scraping has completed.\n",
    "#driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file.close()\n",
    "driver.close()\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
